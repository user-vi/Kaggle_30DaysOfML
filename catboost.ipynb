{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sklearn.neighbors._base\n",
    "# import sys\n",
    "# sys.modules['sklearn.neighbors.base'] = sklearn.neighbors._base\n",
    "\n",
    "import datetime\n",
    "from sklearn import metrics, model_selection, ensemble\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# from imblearn.under_sampling import RandomUnderSampler\n",
    "# from imblearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import plot_precision_recall_curve\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"./test_anomaly.csv\", delimiter=\",\", sep='.')\n",
    "# train = pd.read_csv(\"./train.csv\", delimiter=\",\", sep='.')\n",
    "train = pd.read_csv(\"./train_anomaly.csv\", delimiter=\",\", sep='.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cat0</th>\n",
       "      <th>cat1</th>\n",
       "      <th>cat2</th>\n",
       "      <th>cat3</th>\n",
       "      <th>cat4</th>\n",
       "      <th>cat5</th>\n",
       "      <th>cat6</th>\n",
       "      <th>cat7</th>\n",
       "      <th>cat8</th>\n",
       "      <th>cat9</th>\n",
       "      <th>cont0</th>\n",
       "      <th>cont1</th>\n",
       "      <th>cont2</th>\n",
       "      <th>cont3</th>\n",
       "      <th>cont4</th>\n",
       "      <th>cont5</th>\n",
       "      <th>cont6</th>\n",
       "      <th>cont7</th>\n",
       "      <th>cont8</th>\n",
       "      <th>cont9</th>\n",
       "      <th>cont10</th>\n",
       "      <th>cont11</th>\n",
       "      <th>cont12</th>\n",
       "      <th>cont13</th>\n",
       "      <th>target</th>\n",
       "      <th>anomaly_col</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>C</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>C</td>\n",
       "      <td>N</td>\n",
       "      <td>0.201470</td>\n",
       "      <td>-0.014822</td>\n",
       "      <td>0.669699</td>\n",
       "      <td>0.136278</td>\n",
       "      <td>0.610706</td>\n",
       "      <td>0.400361</td>\n",
       "      <td>0.160266</td>\n",
       "      <td>0.310921</td>\n",
       "      <td>0.389470</td>\n",
       "      <td>0.267559</td>\n",
       "      <td>0.237281</td>\n",
       "      <td>0.377873</td>\n",
       "      <td>0.322401</td>\n",
       "      <td>0.869850</td>\n",
       "      <td>8.113634</td>\n",
       "      <td>Norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>A</td>\n",
       "      <td>F</td>\n",
       "      <td>A</td>\n",
       "      <td>O</td>\n",
       "      <td>0.743068</td>\n",
       "      <td>0.367411</td>\n",
       "      <td>1.021605</td>\n",
       "      <td>0.365798</td>\n",
       "      <td>0.276853</td>\n",
       "      <td>0.533087</td>\n",
       "      <td>0.558922</td>\n",
       "      <td>0.516294</td>\n",
       "      <td>0.594928</td>\n",
       "      <td>0.341439</td>\n",
       "      <td>0.906013</td>\n",
       "      <td>0.921701</td>\n",
       "      <td>0.261975</td>\n",
       "      <td>0.465083</td>\n",
       "      <td>8.481233</td>\n",
       "      <td>Anomaly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>A</td>\n",
       "      <td>D</td>\n",
       "      <td>A</td>\n",
       "      <td>F</td>\n",
       "      <td>0.742708</td>\n",
       "      <td>0.310383</td>\n",
       "      <td>-0.012673</td>\n",
       "      <td>0.576957</td>\n",
       "      <td>0.285074</td>\n",
       "      <td>0.650609</td>\n",
       "      <td>0.375348</td>\n",
       "      <td>0.902567</td>\n",
       "      <td>0.555205</td>\n",
       "      <td>0.843531</td>\n",
       "      <td>0.748809</td>\n",
       "      <td>0.620126</td>\n",
       "      <td>0.541474</td>\n",
       "      <td>0.763846</td>\n",
       "      <td>8.364351</td>\n",
       "      <td>Anomaly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>C</td>\n",
       "      <td>K</td>\n",
       "      <td>0.429551</td>\n",
       "      <td>0.620998</td>\n",
       "      <td>0.577942</td>\n",
       "      <td>0.280610</td>\n",
       "      <td>0.284667</td>\n",
       "      <td>0.668980</td>\n",
       "      <td>0.239061</td>\n",
       "      <td>0.732948</td>\n",
       "      <td>0.679618</td>\n",
       "      <td>0.574844</td>\n",
       "      <td>0.346010</td>\n",
       "      <td>0.714610</td>\n",
       "      <td>0.540150</td>\n",
       "      <td>0.280682</td>\n",
       "      <td>8.049253</td>\n",
       "      <td>Norm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>A</td>\n",
       "      <td>N</td>\n",
       "      <td>1.058291</td>\n",
       "      <td>0.367492</td>\n",
       "      <td>-0.052389</td>\n",
       "      <td>0.232407</td>\n",
       "      <td>0.287595</td>\n",
       "      <td>0.686964</td>\n",
       "      <td>0.420667</td>\n",
       "      <td>0.648182</td>\n",
       "      <td>0.684501</td>\n",
       "      <td>0.956692</td>\n",
       "      <td>1.000773</td>\n",
       "      <td>0.776742</td>\n",
       "      <td>0.625849</td>\n",
       "      <td>0.250823</td>\n",
       "      <td>7.972260</td>\n",
       "      <td>Norm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id cat0 cat1 cat2 cat3 cat4 cat5 cat6 cat7 cat8 cat9     cont0     cont1  \\\n",
       "0   1    B    B    B    C    B    B    A    E    C    N  0.201470 -0.014822   \n",
       "1   2    B    B    A    A    B    D    A    F    A    O  0.743068  0.367411   \n",
       "2   3    A    A    A    C    B    D    A    D    A    F  0.742708  0.310383   \n",
       "3   4    B    B    A    C    B    D    A    E    C    K  0.429551  0.620998   \n",
       "4   6    A    A    A    C    B    D    A    E    A    N  1.058291  0.367492   \n",
       "\n",
       "      cont2     cont3     cont4     cont5     cont6     cont7     cont8  \\\n",
       "0  0.669699  0.136278  0.610706  0.400361  0.160266  0.310921  0.389470   \n",
       "1  1.021605  0.365798  0.276853  0.533087  0.558922  0.516294  0.594928   \n",
       "2 -0.012673  0.576957  0.285074  0.650609  0.375348  0.902567  0.555205   \n",
       "3  0.577942  0.280610  0.284667  0.668980  0.239061  0.732948  0.679618   \n",
       "4 -0.052389  0.232407  0.287595  0.686964  0.420667  0.648182  0.684501   \n",
       "\n",
       "      cont9    cont10    cont11    cont12    cont13    target anomaly_col  \n",
       "0  0.267559  0.237281  0.377873  0.322401  0.869850  8.113634        Norm  \n",
       "1  0.341439  0.906013  0.921701  0.261975  0.465083  8.481233     Anomaly  \n",
       "2  0.843531  0.748809  0.620126  0.541474  0.763846  8.364351     Anomaly  \n",
       "3  0.574844  0.346010  0.714610  0.540150  0.280682  8.049253        Norm  \n",
       "4  0.956692  1.000773  0.776742  0.625849  0.250823  7.972260        Norm  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import Pool, CatBoostRegressor, cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['target'] = 100 * train['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 73.699184       0.532424        73.406661"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train = train.select_dtypes([int, float])\n",
    "cat_train = train.select_dtypes(object)\n",
    "\n",
    "num = list(num_train.drop(['target'],axis=1))\n",
    "cat = list(cat_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import KBinsDiscretizer\n",
    "\n",
    "# pipeline_num = Pipeline(steps=[\n",
    "#     ('imputer', SimpleImputer(strategy='median')),\n",
    "#     ('scaling', StandardScaler()),  \n",
    "#     ('normal', PowerTransformer()), \n",
    "#     ('bins', KBinsDiscretizer())\n",
    "# ])\n",
    "\n",
    "# pipeline_cat = Pipeline(steps=[\n",
    "#     ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "#     ('encoding', OneHotEncoder(handle_unknown='ignore')),\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', pipeline_num, num),\n",
    "        ], remainder=\"passthrough\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = preprocessor.fit_transform(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.drop([\"target\", \"id\"], axis=1)\n",
    "y = train[\"target\"]\n",
    "\n",
    "# X = df[:, :81].astype('str')\n",
    "# y = df[:, 81]\n",
    "\n",
    "\n",
    "train_x, valid_x, train_y, valid_y = train_test_split(X, y, test_size=0.7, random_state=42)\n",
    "\n",
    "\n",
    "# train_pool = Pool(train_x, \n",
    "#               train_y, \n",
    "#               cat_features=list(range(81)))\n",
    "# test_pool = Pool(valid_x, \n",
    "#               valid_y, \n",
    "#               cat_features=list(range(81)))\n",
    "   \n",
    "    \n",
    "train_pool = Pool(train_x, \n",
    "              train_y, \n",
    "              cat_features=list(range(10)) + [24])\n",
    "test_pool = Pool(valid_x, \n",
    "              valid_y, \n",
    "              cat_features=list(range(10)) + [24])\n",
    "\n",
    "def objective(trial):\n",
    "\n",
    "    \n",
    "\n",
    "#     param = {\n",
    "#         \"iterations\": 200, \n",
    "#         \"loss_function\": \"RMSE\",\n",
    "#         \"colsample_bylevel\": trial.suggest_float(\"colsample_bylevel\", 0.01, 0.1),\n",
    "#         \"depth\": trial.suggest_int(\"depth\", 1, 12),\n",
    "#         \"boosting_type\": trial.suggest_categorical(\"boosting_type\", [\"Ordered\", \"Plain\"]),\n",
    "#         \"bootstrap_type\": trial.suggest_categorical(\n",
    "#             \"bootstrap_type\", [\"Bayesian\", \"Bernoulli\", \"MVS\"]\n",
    "#         ),\n",
    "#         \"used_ram_limit\": \"3gb\",\n",
    "#     }\n",
    "\n",
    "#     if param[\"bootstrap_type\"] == \"Bayesian\":\n",
    "#         param[\"bagging_temperature\"] = trial.suggest_float(\"bagging_temperature\", 0, 10)\n",
    "#     elif param[\"bootstrap_type\"] == \"Bernoulli\":\n",
    "#         param[\"subsample\"] = trial.suggest_float(\"subsample\", 0.1, 1)\n",
    "\n",
    "    param = {\n",
    "        'iterations' : trial.suggest_int('iterations', 150, 500),                         \n",
    "        'depth' : trial.suggest_int('depth', 4, 10),                                                    \n",
    "        'random_strength' :trial.suggest_int('random_strength', 0, 100),                       \n",
    "        'bagging_temperature' :trial.suggest_loguniform('bagging_temperature', 0.01, 100.00),\n",
    "        'learning_rate' : trial.suggest_loguniform('learning_rate', 1e-3, 0.5),\n",
    "    }\n",
    "    \n",
    "    gbm = CatBoostRegressor(loss_function =\"RMSE\", **param)\n",
    "\n",
    "    gbm.fit(train_pool, eval_set=test_pool, verbose=0, early_stopping_rounds=100)\n",
    "\n",
    "    preds = gbm.predict(valid_x)\n",
    "    rmse = mean_squared_error(valid_y, preds, squared = False)\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-08-18 22:09:47,069]\u001b[0m A new study created in memory with name: no-name-7fcf42db-dfdf-4562-a3ba-8a55a1dfa389\u001b[0m\n",
      "\u001b[32m[I 2021-08-18 22:12:58,136]\u001b[0m Trial 0 finished with value: 72.6085959501892 and parameters: {'iterations': 425, 'depth': 8, 'random_strength': 36, 'bagging_temperature': 0.22228849444998328, 'learning_rate': 0.13417348761409664}. Best is trial 0 with value: 72.6085959501892.\u001b[0m\n",
      "\u001b[32m[I 2021-08-18 22:15:00,872]\u001b[0m Trial 1 finished with value: 73.71522862914077 and parameters: {'iterations': 496, 'depth': 7, 'random_strength': 32, 'bagging_temperature': 0.15682138316240113, 'learning_rate': 0.02690458065542879}. Best is trial 0 with value: 72.6085959501892.\u001b[0m\n",
      "\u001b[32m[I 2021-08-18 22:16:27,178]\u001b[0m Trial 2 finished with value: 72.72198615929992 and parameters: {'iterations': 225, 'depth': 7, 'random_strength': 37, 'bagging_temperature': 2.8514761744022707, 'learning_rate': 0.35356661987813315}. Best is trial 0 with value: 72.6085959501892.\u001b[0m\n",
      "\u001b[32m[I 2021-08-18 22:16:38,321]\u001b[0m Trial 3 finished with value: 74.52980228816557 and parameters: {'iterations': 197, 'depth': 5, 'random_strength': 85, 'bagging_temperature': 36.563219291138566, 'learning_rate': 0.005131470183985493}. Best is trial 0 with value: 72.6085959501892.\u001b[0m\n",
      "\u001b[32m[I 2021-08-18 22:17:32,095]\u001b[0m Trial 4 finished with value: 72.3936186603107 and parameters: {'iterations': 353, 'depth': 4, 'random_strength': 42, 'bagging_temperature': 0.027785143340172104, 'learning_rate': 0.4840596931491217}. Best is trial 4 with value: 72.3936186603107.\u001b[0m\n",
      "\u001b[32m[I 2021-08-18 22:18:38,431]\u001b[0m Trial 5 finished with value: 74.26333163084134 and parameters: {'iterations': 436, 'depth': 4, 'random_strength': 29, 'bagging_temperature': 28.314791701406378, 'learning_rate': 0.010488435405674843}. Best is trial 4 with value: 72.3936186603107.\u001b[0m\n",
      "\u001b[32m[I 2021-08-18 22:21:12,098]\u001b[0m Trial 6 finished with value: 74.10628895139841 and parameters: {'iterations': 468, 'depth': 10, 'random_strength': 61, 'bagging_temperature': 1.737429390235093, 'learning_rate': 0.01632342632435732}. Best is trial 4 with value: 72.3936186603107.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=50, timeout=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'iterations': 353,\n",
       " 'depth': 4,\n",
       " 'random_strength': 42,\n",
       " 'bagging_temperature': 0.027785143340172104,\n",
       " 'learning_rate': 0.4840596931491217}"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params = study.best_trial.params\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.drop([\"target\", \"id\"], axis=1)\n",
    "y = train.target\n",
    "\n",
    "# X = df[:, :81].astype('str')\n",
    "# y = df[:, 81]\n",
    "\n",
    "train_pool = Pool(X, \n",
    "                  y, \n",
    "                  cat_features=list(range(10)) + [24])\n",
    "\n",
    "params = best_params.copy()\n",
    "params[\"loss_function\"] =\"RMSE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 431.7722339\ttest: 431.7550585\tbest: 431.7550585 (0)\ttotal: 3.2s\tremaining: 18m 47s\n",
      "1:\tlearn: 231.7599604\ttest: 231.7349884\tbest: 231.7349884 (1)\ttotal: 5.73s\tremaining: 16m 46s\n",
      "2:\tlearn: 135.5250449\ttest: 135.4965968\tbest: 135.4965968 (2)\ttotal: 8.22s\tremaining: 15m 58s\n",
      "3:\tlearn: 94.6518414\ttest: 94.6263056\tbest: 94.6263056 (3)\ttotal: 10.1s\tremaining: 14m 42s\n",
      "4:\tlearn: 80.3121667\ttest: 80.2884307\tbest: 80.2884307 (4)\ttotal: 12.3s\tremaining: 14m 17s\n",
      "5:\tlearn: 76.0375540\ttest: 76.0169044\tbest: 76.0169044 (5)\ttotal: 15s\tremaining: 14m 25s\n",
      "6:\tlearn: 74.8400829\ttest: 74.8262366\tbest: 74.8262366 (6)\ttotal: 17.1s\tremaining: 14m 7s\n",
      "7:\tlearn: 74.5221359\ttest: 74.5094926\tbest: 74.5094926 (7)\ttotal: 18.7s\tremaining: 13m 24s\n",
      "8:\tlearn: 74.4303937\ttest: 74.4194265\tbest: 74.4194265 (8)\ttotal: 20.7s\tremaining: 13m 9s\n",
      "9:\tlearn: 74.3733161\ttest: 74.3638512\tbest: 74.3638512 (9)\ttotal: 22.5s\tremaining: 12m 52s\n",
      "10:\tlearn: 74.3659388\ttest: 74.3579125\tbest: 74.3579125 (10)\ttotal: 24.5s\tremaining: 12m 41s\n",
      "11:\tlearn: 74.3536406\ttest: 74.3468500\tbest: 74.3468500 (11)\ttotal: 26s\tremaining: 12m 18s\n",
      "12:\tlearn: 74.3440121\ttest: 74.3384262\tbest: 74.3384262 (12)\ttotal: 28.4s\tremaining: 12m 22s\n",
      "13:\tlearn: 74.3409966\ttest: 74.3377249\tbest: 74.3377249 (13)\ttotal: 30.7s\tremaining: 12m 24s\n",
      "14:\tlearn: 74.2687111\ttest: 74.2686417\tbest: 74.2686417 (14)\ttotal: 32.8s\tremaining: 12m 18s\n",
      "15:\tlearn: 74.2401742\ttest: 74.2437726\tbest: 74.2437726 (15)\ttotal: 35s\tremaining: 12m 17s\n",
      "16:\tlearn: 74.2190068\ttest: 74.2216847\tbest: 74.2216847 (16)\ttotal: 37.4s\tremaining: 12m 18s\n",
      "17:\tlearn: 74.1544633\ttest: 74.1616815\tbest: 74.1616815 (17)\ttotal: 39.9s\tremaining: 12m 23s\n",
      "18:\tlearn: 74.1421162\ttest: 74.1507833\tbest: 74.1507833 (18)\ttotal: 41.8s\tremaining: 12m 15s\n",
      "19:\tlearn: 74.1367758\ttest: 74.1482629\tbest: 74.1482629 (19)\ttotal: 44s\tremaining: 12m 13s\n",
      "20:\tlearn: 74.0998846\ttest: 74.1115898\tbest: 74.1115898 (20)\ttotal: 46.5s\tremaining: 12m 15s\n",
      "21:\tlearn: 74.0506066\ttest: 74.0623580\tbest: 74.0623580 (21)\ttotal: 48.8s\tremaining: 12m 13s\n",
      "22:\tlearn: 74.0258092\ttest: 74.0372109\tbest: 74.0372109 (22)\ttotal: 51.2s\tremaining: 12m 14s\n",
      "23:\tlearn: 74.0169845\ttest: 74.0298145\tbest: 74.0298145 (23)\ttotal: 52.9s\tremaining: 12m 5s\n",
      "24:\tlearn: 73.9774343\ttest: 73.9925249\tbest: 73.9925249 (24)\ttotal: 55.4s\tremaining: 12m 6s\n",
      "25:\tlearn: 73.9634000\ttest: 73.9766251\tbest: 73.9766251 (25)\ttotal: 57.5s\tremaining: 12m 2s\n",
      "26:\tlearn: 73.9445890\ttest: 73.9579876\tbest: 73.9579876 (26)\ttotal: 59.5s\tremaining: 11m 58s\n",
      "27:\tlearn: 73.9122526\ttest: 73.9277054\tbest: 73.9277054 (27)\ttotal: 1m 2s\tremaining: 11m 59s\n",
      "28:\tlearn: 73.8693637\ttest: 73.8880832\tbest: 73.8880832 (28)\ttotal: 1m 4s\tremaining: 12m 2s\n",
      "29:\tlearn: 73.8065304\ttest: 73.8228367\tbest: 73.8228367 (29)\ttotal: 1m 7s\tremaining: 12m 3s\n",
      "30:\tlearn: 73.7439402\ttest: 73.7652261\tbest: 73.7652261 (30)\ttotal: 1m 9s\tremaining: 12m 2s\n",
      "31:\tlearn: 73.6703680\ttest: 73.6932345\tbest: 73.6932345 (31)\ttotal: 1m 12s\tremaining: 12m 4s\n",
      "32:\tlearn: 73.5898958\ttest: 73.6222233\tbest: 73.6222233 (32)\ttotal: 1m 14s\tremaining: 12m 6s\n",
      "33:\tlearn: 73.5101170\ttest: 73.5400964\tbest: 73.5400964 (33)\ttotal: 1m 17s\tremaining: 12m 6s\n",
      "34:\tlearn: 73.4283490\ttest: 73.4622480\tbest: 73.4622480 (34)\ttotal: 1m 20s\tremaining: 12m 7s\n",
      "35:\tlearn: 73.3510303\ttest: 73.3915965\tbest: 73.3915965 (35)\ttotal: 1m 22s\tremaining: 12m 8s\n",
      "36:\tlearn: 73.2909992\ttest: 73.3361016\tbest: 73.3361016 (36)\ttotal: 1m 25s\tremaining: 12m 9s\n",
      "37:\tlearn: 73.2384938\ttest: 73.2893503\tbest: 73.2893503 (37)\ttotal: 1m 28s\tremaining: 12m 10s\n",
      "38:\tlearn: 73.1916764\ttest: 73.2452034\tbest: 73.2452034 (38)\ttotal: 1m 30s\tremaining: 12m 9s\n",
      "39:\tlearn: 73.1517757\ttest: 73.2045933\tbest: 73.2045933 (39)\ttotal: 1m 33s\tremaining: 12m 9s\n",
      "40:\tlearn: 73.1124245\ttest: 73.1677292\tbest: 73.1677292 (40)\ttotal: 1m 35s\tremaining: 12m 9s\n",
      "41:\tlearn: 73.0715658\ttest: 73.1342450\tbest: 73.1342450 (41)\ttotal: 1m 38s\tremaining: 12m 9s\n",
      "42:\tlearn: 73.0368743\ttest: 73.1022255\tbest: 73.1022255 (42)\ttotal: 1m 41s\tremaining: 12m 8s\n",
      "43:\tlearn: 72.9986675\ttest: 73.0645237\tbest: 73.0645237 (43)\ttotal: 1m 43s\tremaining: 12m 8s\n",
      "44:\tlearn: 72.9718478\ttest: 73.0375051\tbest: 73.0375051 (44)\ttotal: 1m 46s\tremaining: 12m 8s\n",
      "45:\tlearn: 72.9443474\ttest: 73.0121972\tbest: 73.0121972 (45)\ttotal: 1m 49s\tremaining: 12m 8s\n",
      "46:\tlearn: 72.9180649\ttest: 72.9930447\tbest: 72.9930447 (46)\ttotal: 1m 51s\tremaining: 12m 7s\n",
      "47:\tlearn: 72.8916099\ttest: 72.9715530\tbest: 72.9715530 (47)\ttotal: 1m 54s\tremaining: 12m 6s\n",
      "48:\tlearn: 72.8717417\ttest: 72.9547258\tbest: 72.9547258 (48)\ttotal: 1m 56s\tremaining: 12m 5s\n",
      "49:\tlearn: 72.8536424\ttest: 72.9416768\tbest: 72.9416768 (49)\ttotal: 1m 59s\tremaining: 12m 4s\n",
      "50:\tlearn: 72.8332700\ttest: 72.9294519\tbest: 72.9294519 (50)\ttotal: 2m 2s\tremaining: 12m 3s\n",
      "51:\tlearn: 72.8158316\ttest: 72.9147714\tbest: 72.9147714 (51)\ttotal: 2m 4s\tremaining: 12m 2s\n",
      "52:\tlearn: 72.7920621\ttest: 72.8961720\tbest: 72.8961720 (52)\ttotal: 2m 7s\tremaining: 12m\n",
      "53:\tlearn: 72.7656049\ttest: 72.8702522\tbest: 72.8702522 (53)\ttotal: 2m 9s\tremaining: 11m 59s\n",
      "54:\tlearn: 72.7473949\ttest: 72.8522683\tbest: 72.8522683 (54)\ttotal: 2m 12s\tremaining: 11m 58s\n",
      "55:\tlearn: 72.7266040\ttest: 72.8354053\tbest: 72.8354053 (55)\ttotal: 2m 15s\tremaining: 11m 56s\n",
      "56:\tlearn: 72.7059160\ttest: 72.8167538\tbest: 72.8167538 (56)\ttotal: 2m 17s\tremaining: 11m 55s\n",
      "57:\tlearn: 72.6799075\ttest: 72.7951641\tbest: 72.7951641 (57)\ttotal: 2m 20s\tremaining: 11m 54s\n",
      "58:\tlearn: 72.6582012\ttest: 72.7743565\tbest: 72.7743565 (58)\ttotal: 2m 23s\tremaining: 11m 53s\n",
      "59:\tlearn: 72.6390633\ttest: 72.7599198\tbest: 72.7599198 (59)\ttotal: 2m 25s\tremaining: 11m 51s\n",
      "60:\tlearn: 72.6194169\ttest: 72.7438020\tbest: 72.7438020 (60)\ttotal: 2m 28s\tremaining: 11m 50s\n",
      "61:\tlearn: 72.5974324\ttest: 72.7247264\tbest: 72.7247264 (61)\ttotal: 2m 31s\tremaining: 11m 48s\n",
      "62:\tlearn: 72.5810126\ttest: 72.7123496\tbest: 72.7123496 (62)\ttotal: 2m 33s\tremaining: 11m 47s\n",
      "63:\tlearn: 72.5639517\ttest: 72.6959252\tbest: 72.6959252 (63)\ttotal: 2m 36s\tremaining: 11m 47s\n",
      "64:\tlearn: 72.5447049\ttest: 72.6771016\tbest: 72.6771016 (64)\ttotal: 2m 39s\tremaining: 11m 45s\n",
      "65:\tlearn: 72.5298582\ttest: 72.6660207\tbest: 72.6660207 (65)\ttotal: 2m 41s\tremaining: 11m 43s\n",
      "66:\tlearn: 72.5130982\ttest: 72.6511552\tbest: 72.6511552 (66)\ttotal: 2m 44s\tremaining: 11m 41s\n",
      "67:\tlearn: 72.5001146\ttest: 72.6423471\tbest: 72.6423471 (67)\ttotal: 2m 47s\tremaining: 11m 40s\n",
      "68:\tlearn: 72.4851686\ttest: 72.6304642\tbest: 72.6304642 (68)\ttotal: 2m 49s\tremaining: 11m 39s\n",
      "69:\tlearn: 72.4719378\ttest: 72.6198650\tbest: 72.6198650 (69)\ttotal: 2m 52s\tremaining: 11m 37s\n",
      "70:\tlearn: 72.4553453\ttest: 72.6064506\tbest: 72.6064506 (70)\ttotal: 2m 55s\tremaining: 11m 36s\n",
      "71:\tlearn: 72.4429037\ttest: 72.5963618\tbest: 72.5963618 (71)\ttotal: 2m 57s\tremaining: 11m 34s\n",
      "72:\tlearn: 72.4258119\ttest: 72.5849938\tbest: 72.5849938 (72)\ttotal: 3m\tremaining: 11m 32s\n",
      "73:\tlearn: 72.4104913\ttest: 72.5732297\tbest: 72.5732297 (73)\ttotal: 3m 3s\tremaining: 11m 31s\n",
      "74:\tlearn: 72.3995510\ttest: 72.5658830\tbest: 72.5658830 (74)\ttotal: 3m 6s\tremaining: 11m 29s\n",
      "75:\tlearn: 72.3851203\ttest: 72.5559588\tbest: 72.5559588 (75)\ttotal: 3m 8s\tremaining: 11m 27s\n",
      "76:\tlearn: 72.3705064\ttest: 72.5466739\tbest: 72.5466739 (76)\ttotal: 3m 11s\tremaining: 11m 25s\n",
      "77:\tlearn: 72.3590552\ttest: 72.5405101\tbest: 72.5405101 (77)\ttotal: 3m 13s\tremaining: 11m 23s\n",
      "78:\tlearn: 72.3453641\ttest: 72.5279434\tbest: 72.5279434 (78)\ttotal: 3m 16s\tremaining: 11m 21s\n",
      "79:\tlearn: 72.3332445\ttest: 72.5205808\tbest: 72.5205808 (79)\ttotal: 3m 19s\tremaining: 11m 19s\n",
      "80:\tlearn: 72.3222667\ttest: 72.5130445\tbest: 72.5130445 (80)\ttotal: 3m 21s\tremaining: 11m 17s\n",
      "81:\tlearn: 72.3102673\ttest: 72.5058181\tbest: 72.5058181 (81)\ttotal: 3m 24s\tremaining: 11m 15s\n",
      "82:\tlearn: 72.3005862\ttest: 72.5033078\tbest: 72.5033078 (82)\ttotal: 3m 27s\tremaining: 11m 13s\n",
      "83:\tlearn: 72.2899775\ttest: 72.4954410\tbest: 72.4954410 (83)\ttotal: 3m 29s\tremaining: 11m 11s\n",
      "84:\tlearn: 72.2792113\ttest: 72.4894833\tbest: 72.4894833 (84)\ttotal: 3m 32s\tremaining: 11m 9s\n",
      "85:\tlearn: 72.2685961\ttest: 72.4824992\tbest: 72.4824992 (85)\ttotal: 3m 34s\tremaining: 11m 6s\n",
      "86:\tlearn: 72.2586103\ttest: 72.4766539\tbest: 72.4766539 (86)\ttotal: 3m 37s\tremaining: 11m 5s\n",
      "87:\tlearn: 72.2472248\ttest: 72.4686328\tbest: 72.4686328 (87)\ttotal: 3m 40s\tremaining: 11m 2s\n",
      "88:\tlearn: 72.2358577\ttest: 72.4598408\tbest: 72.4598408 (88)\ttotal: 3m 42s\tremaining: 11m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89:\tlearn: 72.2286105\ttest: 72.4547769\tbest: 72.4547769 (89)\ttotal: 3m 45s\tremaining: 10m 58s\n",
      "90:\tlearn: 72.2200838\ttest: 72.4494615\tbest: 72.4494615 (90)\ttotal: 3m 47s\tremaining: 10m 56s\n",
      "91:\tlearn: 72.2109570\ttest: 72.4434042\tbest: 72.4434042 (91)\ttotal: 3m 50s\tremaining: 10m 53s\n",
      "92:\tlearn: 72.2029820\ttest: 72.4403089\tbest: 72.4403089 (92)\ttotal: 3m 53s\tremaining: 10m 52s\n",
      "93:\tlearn: 72.1912775\ttest: 72.4311930\tbest: 72.4311930 (93)\ttotal: 3m 55s\tremaining: 10m 50s\n",
      "94:\tlearn: 72.1794469\ttest: 72.4223530\tbest: 72.4223530 (94)\ttotal: 3m 58s\tremaining: 10m 47s\n",
      "95:\tlearn: 72.1688349\ttest: 72.4140178\tbest: 72.4140178 (95)\ttotal: 4m 1s\tremaining: 10m 45s\n",
      "96:\tlearn: 72.1623097\ttest: 72.4112478\tbest: 72.4112478 (96)\ttotal: 4m 3s\tremaining: 10m 43s\n",
      "97:\tlearn: 72.1532669\ttest: 72.4084629\tbest: 72.4084629 (97)\ttotal: 4m 6s\tremaining: 10m 41s\n",
      "98:\tlearn: 72.1459380\ttest: 72.4039784\tbest: 72.4039784 (98)\ttotal: 4m 9s\tremaining: 10m 39s\n",
      "99:\tlearn: 72.1352346\ttest: 72.3959984\tbest: 72.3959984 (99)\ttotal: 4m 12s\tremaining: 10m 37s\n",
      "100:\tlearn: 72.1253260\ttest: 72.3885640\tbest: 72.3885640 (100)\ttotal: 4m 14s\tremaining: 10m 35s\n",
      "101:\tlearn: 72.1150079\ttest: 72.3814008\tbest: 72.3814008 (101)\ttotal: 4m 17s\tremaining: 10m 33s\n",
      "102:\tlearn: 72.1058677\ttest: 72.3758373\tbest: 72.3758373 (102)\ttotal: 4m 20s\tremaining: 10m 31s\n",
      "103:\tlearn: 72.0936758\ttest: 72.3675025\tbest: 72.3675025 (103)\ttotal: 4m 22s\tremaining: 10m 29s\n",
      "104:\tlearn: 72.0870554\ttest: 72.3643358\tbest: 72.3643358 (104)\ttotal: 4m 25s\tremaining: 10m 26s\n",
      "105:\tlearn: 72.0788975\ttest: 72.3572538\tbest: 72.3572538 (105)\ttotal: 4m 28s\tremaining: 10m 25s\n",
      "106:\tlearn: 72.0710827\ttest: 72.3542845\tbest: 72.3542845 (106)\ttotal: 4m 30s\tremaining: 10m 23s\n",
      "107:\tlearn: 72.0637841\ttest: 72.3513452\tbest: 72.3513452 (107)\ttotal: 4m 33s\tremaining: 10m 20s\n",
      "108:\tlearn: 72.0558883\ttest: 72.3452232\tbest: 72.3452232 (108)\ttotal: 4m 36s\tremaining: 10m 18s\n",
      "109:\tlearn: 72.0484793\ttest: 72.3420219\tbest: 72.3420219 (109)\ttotal: 4m 39s\tremaining: 10m 16s\n",
      "110:\tlearn: 72.0402255\ttest: 72.3370785\tbest: 72.3370785 (110)\ttotal: 4m 41s\tremaining: 10m 14s\n",
      "111:\tlearn: 72.0329099\ttest: 72.3347166\tbest: 72.3347166 (111)\ttotal: 4m 44s\tremaining: 10m 11s\n",
      "112:\tlearn: 72.0275711\ttest: 72.3332582\tbest: 72.3332582 (112)\ttotal: 4m 46s\tremaining: 10m 9s\n",
      "113:\tlearn: 72.0219192\ttest: 72.3302654\tbest: 72.3302654 (113)\ttotal: 4m 49s\tremaining: 10m 6s\n",
      "114:\tlearn: 72.0127966\ttest: 72.3265870\tbest: 72.3265870 (114)\ttotal: 4m 52s\tremaining: 10m 4s\n",
      "115:\tlearn: 72.0061631\ttest: 72.3224509\tbest: 72.3224509 (115)\ttotal: 4m 54s\tremaining: 10m 2s\n",
      "116:\tlearn: 71.9990051\ttest: 72.3179398\tbest: 72.3179398 (116)\ttotal: 4m 57s\tremaining: 10m\n",
      "117:\tlearn: 71.9911959\ttest: 72.3154552\tbest: 72.3154552 (117)\ttotal: 5m\tremaining: 9m 58s\n",
      "118:\tlearn: 71.9869832\ttest: 72.3140727\tbest: 72.3140727 (118)\ttotal: 5m 3s\tremaining: 9m 56s\n",
      "119:\tlearn: 71.9796505\ttest: 72.3082751\tbest: 72.3082751 (119)\ttotal: 5m 6s\tremaining: 9m 54s\n",
      "120:\tlearn: 71.9726091\ttest: 72.3061967\tbest: 72.3061967 (120)\ttotal: 5m 9s\tremaining: 9m 52s\n",
      "121:\tlearn: 71.9660003\ttest: 72.3033994\tbest: 72.3033994 (121)\ttotal: 5m 11s\tremaining: 9m 50s\n",
      "122:\tlearn: 71.9583283\ttest: 72.2998265\tbest: 72.2998265 (122)\ttotal: 5m 14s\tremaining: 9m 48s\n",
      "123:\tlearn: 71.9511239\ttest: 72.2961745\tbest: 72.2961745 (123)\ttotal: 5m 17s\tremaining: 9m 45s\n",
      "124:\tlearn: 71.9460451\ttest: 72.2923202\tbest: 72.2923202 (124)\ttotal: 5m 19s\tremaining: 9m 43s\n",
      "125:\tlearn: 71.9417796\ttest: 72.2906926\tbest: 72.2906926 (125)\ttotal: 5m 22s\tremaining: 9m 40s\n",
      "126:\tlearn: 71.9336100\ttest: 72.2863944\tbest: 72.2863944 (126)\ttotal: 5m 25s\tremaining: 9m 38s\n",
      "127:\tlearn: 71.9270960\ttest: 72.2835366\tbest: 72.2835366 (127)\ttotal: 5m 27s\tremaining: 9m 36s\n",
      "128:\tlearn: 71.9197975\ttest: 72.2801404\tbest: 72.2801404 (128)\ttotal: 5m 31s\tremaining: 9m 34s\n",
      "129:\tlearn: 71.9112743\ttest: 72.2752974\tbest: 72.2752974 (129)\ttotal: 5m 33s\tremaining: 9m 32s\n",
      "130:\tlearn: 71.9050718\ttest: 72.2746351\tbest: 72.2746351 (130)\ttotal: 5m 36s\tremaining: 9m 30s\n",
      "131:\tlearn: 71.8968583\ttest: 72.2686843\tbest: 72.2686843 (131)\ttotal: 5m 39s\tremaining: 9m 28s\n",
      "132:\tlearn: 71.8928256\ttest: 72.2674364\tbest: 72.2674364 (132)\ttotal: 5m 42s\tremaining: 9m 25s\n",
      "133:\tlearn: 71.8859891\ttest: 72.2641670\tbest: 72.2641670 (133)\ttotal: 5m 44s\tremaining: 9m 23s\n",
      "134:\tlearn: 71.8806033\ttest: 72.2648054\tbest: 72.2641670 (133)\ttotal: 5m 47s\tremaining: 9m 20s\n",
      "135:\tlearn: 71.8755112\ttest: 72.2620307\tbest: 72.2620307 (135)\ttotal: 5m 50s\tremaining: 9m 19s\n",
      "136:\tlearn: 71.8716290\ttest: 72.2620606\tbest: 72.2620307 (135)\ttotal: 5m 52s\tremaining: 9m 16s\n",
      "137:\tlearn: 71.8663480\ttest: 72.2616210\tbest: 72.2616210 (137)\ttotal: 5m 55s\tremaining: 9m 13s\n",
      "138:\tlearn: 71.8567444\ttest: 72.2549088\tbest: 72.2549088 (138)\ttotal: 5m 58s\tremaining: 9m 11s\n",
      "139:\tlearn: 71.8503876\ttest: 72.2529125\tbest: 72.2529125 (139)\ttotal: 6m\tremaining: 9m 8s\n",
      "140:\tlearn: 71.8451058\ttest: 72.2508374\tbest: 72.2508374 (140)\ttotal: 6m 3s\tremaining: 9m 6s\n",
      "141:\tlearn: 71.8347749\ttest: 72.2395856\tbest: 72.2395856 (141)\ttotal: 6m 6s\tremaining: 9m 4s\n",
      "142:\tlearn: 71.8304641\ttest: 72.2376536\tbest: 72.2376536 (142)\ttotal: 6m 8s\tremaining: 9m 1s\n",
      "143:\tlearn: 71.8256085\ttest: 72.2369102\tbest: 72.2369102 (143)\ttotal: 6m 11s\tremaining: 8m 59s\n",
      "144:\tlearn: 71.8208394\ttest: 72.2372470\tbest: 72.2369102 (143)\ttotal: 6m 14s\tremaining: 8m 56s\n",
      "145:\tlearn: 71.8136617\ttest: 72.2354660\tbest: 72.2354660 (145)\ttotal: 6m 16s\tremaining: 8m 54s\n",
      "146:\tlearn: 71.8084420\ttest: 72.2337460\tbest: 72.2337460 (146)\ttotal: 6m 19s\tremaining: 8m 51s\n",
      "147:\tlearn: 71.8020334\ttest: 72.2305999\tbest: 72.2305999 (147)\ttotal: 6m 22s\tremaining: 8m 49s\n",
      "148:\tlearn: 71.7965838\ttest: 72.2299767\tbest: 72.2299767 (148)\ttotal: 6m 24s\tremaining: 8m 47s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-109-898cd7020612>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m             \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m             \u001b[0mfold_count\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m             plot=False))\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\catboost\\core.py\u001b[0m in \u001b[0;36mcv\u001b[1;34m(pool, params, dtrain, iterations, num_boost_round, fold_count, nfold, inverted, partition_random_seed, seed, shuffle, logging_level, stratified, as_pandas, metric_period, verbose, verbose_eval, plot, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, folds, type)\u001b[0m\n\u001b[0;32m   5323\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mlog_fixup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplot_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0m_get_train_dir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5324\u001b[0m         return _cv(params, pool, fold_count, inverted, partition_random_seed, shuffle, stratified,\n\u001b[1;32m-> 5325\u001b[1;33m                    as_pandas, folds, type)\n\u001b[0m\u001b[0;32m   5326\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5327\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._cv\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m_catboost.pyx\u001b[0m in \u001b[0;36m_catboost._cv\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(cv(train_pool,\n",
    "            params,\n",
    "            fold_count=5, \n",
    "            plot=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 74.4514640\ttotal: 332ms\tremaining: 1m 56s\n",
      "1:\tlearn: 74.4416766\ttotal: 713ms\tremaining: 2m 5s\n",
      "2:\tlearn: 74.4101600\ttotal: 1.05s\tremaining: 2m 2s\n",
      "3:\tlearn: 74.3612299\ttotal: 1.35s\tremaining: 1m 58s\n",
      "4:\tlearn: 74.3188670\ttotal: 1.66s\tremaining: 1m 55s\n",
      "5:\tlearn: 74.2407649\ttotal: 1.8s\tremaining: 1m 44s\n",
      "6:\tlearn: 74.2359852\ttotal: 2.07s\tremaining: 1m 42s\n",
      "7:\tlearn: 74.1987077\ttotal: 2.37s\tremaining: 1m 42s\n",
      "8:\tlearn: 74.1709004\ttotal: 2.67s\tremaining: 1m 42s\n",
      "9:\tlearn: 74.1659685\ttotal: 3.05s\tremaining: 1m 44s\n",
      "10:\tlearn: 74.1557542\ttotal: 3.44s\tremaining: 1m 46s\n",
      "11:\tlearn: 74.1435253\ttotal: 3.85s\tremaining: 1m 49s\n",
      "12:\tlearn: 74.0922613\ttotal: 4.17s\tremaining: 1m 49s\n",
      "13:\tlearn: 74.0595707\ttotal: 4.47s\tremaining: 1m 48s\n",
      "14:\tlearn: 74.0595707\ttotal: 4.54s\tremaining: 1m 42s\n",
      "15:\tlearn: 74.0588860\ttotal: 4.72s\tremaining: 1m 39s\n",
      "16:\tlearn: 74.0588860\ttotal: 4.79s\tremaining: 1m 34s\n",
      "17:\tlearn: 74.0360313\ttotal: 5.08s\tremaining: 1m 34s\n",
      "18:\tlearn: 74.0360305\ttotal: 5.21s\tremaining: 1m 31s\n",
      "19:\tlearn: 74.0004880\ttotal: 5.46s\tremaining: 1m 30s\n",
      "20:\tlearn: 73.9872765\ttotal: 5.67s\tremaining: 1m 29s\n",
      "21:\tlearn: 73.9799430\ttotal: 5.91s\tremaining: 1m 28s\n",
      "22:\tlearn: 73.9395780\ttotal: 6.27s\tremaining: 1m 29s\n",
      "23:\tlearn: 73.9292855\ttotal: 6.53s\tremaining: 1m 29s\n",
      "24:\tlearn: 73.9292855\ttotal: 6.57s\tremaining: 1m 26s\n",
      "25:\tlearn: 73.9238793\ttotal: 6.88s\tremaining: 1m 26s\n",
      "26:\tlearn: 73.9144866\ttotal: 7.2s\tremaining: 1m 26s\n",
      "27:\tlearn: 73.8583117\ttotal: 7.51s\tremaining: 1m 27s\n",
      "28:\tlearn: 73.8200883\ttotal: 7.82s\tremaining: 1m 27s\n",
      "29:\tlearn: 73.7588748\ttotal: 8.16s\tremaining: 1m 27s\n",
      "30:\tlearn: 73.6888101\ttotal: 8.55s\tremaining: 1m 28s\n",
      "31:\tlearn: 73.6170871\ttotal: 8.94s\tremaining: 1m 29s\n",
      "32:\tlearn: 73.5575545\ttotal: 9.35s\tremaining: 1m 30s\n",
      "33:\tlearn: 73.5015380\ttotal: 9.79s\tremaining: 1m 31s\n",
      "34:\tlearn: 73.3887938\ttotal: 10.1s\tremaining: 1m 32s\n",
      "35:\tlearn: 73.3177523\ttotal: 10.5s\tremaining: 1m 32s\n",
      "36:\tlearn: 73.2785686\ttotal: 10.8s\tremaining: 1m 31s\n",
      "37:\tlearn: 73.2150437\ttotal: 11.1s\tremaining: 1m 31s\n",
      "38:\tlearn: 73.1789763\ttotal: 11.4s\tremaining: 1m 31s\n",
      "39:\tlearn: 73.1426283\ttotal: 11.7s\tremaining: 1m 31s\n",
      "40:\tlearn: 73.1149484\ttotal: 12s\tremaining: 1m 31s\n",
      "41:\tlearn: 73.0861438\ttotal: 12.3s\tremaining: 1m 31s\n",
      "42:\tlearn: 73.0559607\ttotal: 12.6s\tremaining: 1m 30s\n",
      "43:\tlearn: 73.0284026\ttotal: 12.9s\tremaining: 1m 30s\n",
      "44:\tlearn: 72.9684709\ttotal: 13.2s\tremaining: 1m 30s\n",
      "45:\tlearn: 72.9469413\ttotal: 13.5s\tremaining: 1m 30s\n",
      "46:\tlearn: 72.9235996\ttotal: 13.8s\tremaining: 1m 30s\n",
      "47:\tlearn: 72.9074228\ttotal: 14.2s\tremaining: 1m 30s\n",
      "48:\tlearn: 72.8551411\ttotal: 14.5s\tremaining: 1m 30s\n",
      "49:\tlearn: 72.8304542\ttotal: 14.9s\tremaining: 1m 30s\n",
      "50:\tlearn: 72.8122906\ttotal: 15.2s\tremaining: 1m 30s\n",
      "51:\tlearn: 72.7799937\ttotal: 15.5s\tremaining: 1m 29s\n",
      "52:\tlearn: 72.7565135\ttotal: 15.9s\tremaining: 1m 29s\n",
      "53:\tlearn: 72.7196587\ttotal: 16.2s\tremaining: 1m 29s\n",
      "54:\tlearn: 72.6951999\ttotal: 16.5s\tremaining: 1m 29s\n",
      "55:\tlearn: 72.6767575\ttotal: 16.9s\tremaining: 1m 29s\n",
      "56:\tlearn: 72.6555982\ttotal: 17.2s\tremaining: 1m 29s\n",
      "57:\tlearn: 72.6423942\ttotal: 17.5s\tremaining: 1m 29s\n",
      "58:\tlearn: 72.6184083\ttotal: 17.9s\tremaining: 1m 28s\n",
      "59:\tlearn: 72.6061401\ttotal: 18.2s\tremaining: 1m 28s\n",
      "60:\tlearn: 72.5878280\ttotal: 18.6s\tremaining: 1m 28s\n",
      "61:\tlearn: 72.5730507\ttotal: 18.9s\tremaining: 1m 28s\n",
      "62:\tlearn: 72.5527932\ttotal: 19.3s\tremaining: 1m 28s\n",
      "63:\tlearn: 72.5388712\ttotal: 19.6s\tremaining: 1m 28s\n",
      "64:\tlearn: 72.5253048\ttotal: 19.9s\tremaining: 1m 28s\n",
      "65:\tlearn: 72.5079185\ttotal: 20.3s\tremaining: 1m 28s\n",
      "66:\tlearn: 72.4988262\ttotal: 20.6s\tremaining: 1m 28s\n",
      "67:\tlearn: 72.4870988\ttotal: 21s\tremaining: 1m 27s\n",
      "68:\tlearn: 72.4786793\ttotal: 21.3s\tremaining: 1m 27s\n",
      "69:\tlearn: 72.4690781\ttotal: 21.7s\tremaining: 1m 27s\n",
      "70:\tlearn: 72.4567144\ttotal: 22.1s\tremaining: 1m 27s\n",
      "71:\tlearn: 72.4358230\ttotal: 22.5s\tremaining: 1m 27s\n",
      "72:\tlearn: 72.4209804\ttotal: 22.9s\tremaining: 1m 27s\n",
      "73:\tlearn: 72.4102447\ttotal: 23.3s\tremaining: 1m 27s\n",
      "74:\tlearn: 72.3960353\ttotal: 23.6s\tremaining: 1m 27s\n",
      "75:\tlearn: 72.3896183\ttotal: 24s\tremaining: 1m 27s\n",
      "76:\tlearn: 72.3721281\ttotal: 24.4s\tremaining: 1m 27s\n",
      "77:\tlearn: 72.3602255\ttotal: 24.7s\tremaining: 1m 27s\n",
      "78:\tlearn: 72.3539499\ttotal: 25.1s\tremaining: 1m 26s\n",
      "79:\tlearn: 72.3302845\ttotal: 25.4s\tremaining: 1m 26s\n",
      "80:\tlearn: 72.3082746\ttotal: 25.8s\tremaining: 1m 26s\n",
      "81:\tlearn: 72.2922620\ttotal: 26.1s\tremaining: 1m 26s\n",
      "82:\tlearn: 72.2838389\ttotal: 26.4s\tremaining: 1m 25s\n",
      "83:\tlearn: 72.2622514\ttotal: 26.8s\tremaining: 1m 25s\n",
      "84:\tlearn: 72.2548442\ttotal: 27.1s\tremaining: 1m 25s\n",
      "85:\tlearn: 72.2443396\ttotal: 27.5s\tremaining: 1m 25s\n",
      "86:\tlearn: 72.2351395\ttotal: 27.8s\tremaining: 1m 25s\n",
      "87:\tlearn: 72.2263591\ttotal: 28.2s\tremaining: 1m 24s\n",
      "88:\tlearn: 72.2175348\ttotal: 28.5s\tremaining: 1m 24s\n",
      "89:\tlearn: 72.2074544\ttotal: 28.8s\tremaining: 1m 24s\n",
      "90:\tlearn: 72.1962432\ttotal: 29.2s\tremaining: 1m 24s\n",
      "91:\tlearn: 72.1928697\ttotal: 29.5s\tremaining: 1m 23s\n",
      "92:\tlearn: 72.1817630\ttotal: 29.9s\tremaining: 1m 23s\n",
      "93:\tlearn: 72.1756676\ttotal: 30.2s\tremaining: 1m 23s\n",
      "94:\tlearn: 72.1604875\ttotal: 30.6s\tremaining: 1m 23s\n",
      "95:\tlearn: 72.1495831\ttotal: 30.9s\tremaining: 1m 22s\n",
      "96:\tlearn: 72.1412650\ttotal: 31.3s\tremaining: 1m 22s\n",
      "97:\tlearn: 72.1352486\ttotal: 31.7s\tremaining: 1m 22s\n",
      "98:\tlearn: 72.1247727\ttotal: 32s\tremaining: 1m 22s\n",
      "99:\tlearn: 72.1149592\ttotal: 32.4s\tremaining: 1m 21s\n",
      "100:\tlearn: 72.1143556\ttotal: 32.7s\tremaining: 1m 21s\n",
      "101:\tlearn: 72.0977825\ttotal: 33s\tremaining: 1m 21s\n",
      "102:\tlearn: 72.0931696\ttotal: 33.4s\tremaining: 1m 21s\n",
      "103:\tlearn: 72.0875846\ttotal: 33.7s\tremaining: 1m 20s\n",
      "104:\tlearn: 72.0793891\ttotal: 34.1s\tremaining: 1m 20s\n",
      "105:\tlearn: 72.0710271\ttotal: 34.4s\tremaining: 1m 20s\n",
      "106:\tlearn: 72.0651202\ttotal: 34.8s\tremaining: 1m 20s\n",
      "107:\tlearn: 72.0542707\ttotal: 35.2s\tremaining: 1m 19s\n",
      "108:\tlearn: 72.0469203\ttotal: 35.6s\tremaining: 1m 19s\n",
      "109:\tlearn: 72.0394501\ttotal: 35.9s\tremaining: 1m 19s\n",
      "110:\tlearn: 72.0330784\ttotal: 36.3s\tremaining: 1m 19s\n",
      "111:\tlearn: 72.0255604\ttotal: 36.6s\tremaining: 1m 18s\n",
      "112:\tlearn: 72.0191410\ttotal: 37s\tremaining: 1m 18s\n",
      "113:\tlearn: 72.0099426\ttotal: 37.3s\tremaining: 1m 18s\n",
      "114:\tlearn: 72.0027274\ttotal: 37.7s\tremaining: 1m 17s\n",
      "115:\tlearn: 71.9960502\ttotal: 38s\tremaining: 1m 17s\n",
      "116:\tlearn: 71.9885778\ttotal: 38.4s\tremaining: 1m 17s\n",
      "117:\tlearn: 71.9826827\ttotal: 38.8s\tremaining: 1m 17s\n",
      "118:\tlearn: 71.9724759\ttotal: 39.1s\tremaining: 1m 16s\n",
      "119:\tlearn: 71.9640817\ttotal: 39.5s\tremaining: 1m 16s\n",
      "120:\tlearn: 71.9605389\ttotal: 39.8s\tremaining: 1m 16s\n",
      "121:\tlearn: 71.9549884\ttotal: 40.2s\tremaining: 1m 16s\n",
      "122:\tlearn: 71.9487006\ttotal: 40.6s\tremaining: 1m 15s\n",
      "123:\tlearn: 71.9394283\ttotal: 40.9s\tremaining: 1m 15s\n",
      "124:\tlearn: 71.9330479\ttotal: 41.3s\tremaining: 1m 15s\n",
      "125:\tlearn: 71.9267028\ttotal: 41.6s\tremaining: 1m 15s\n",
      "126:\tlearn: 71.9198795\ttotal: 42s\tremaining: 1m 14s\n",
      "127:\tlearn: 71.9103486\ttotal: 42.3s\tremaining: 1m 14s\n",
      "128:\tlearn: 71.9065762\ttotal: 42.6s\tremaining: 1m 14s\n",
      "129:\tlearn: 71.9014745\ttotal: 43s\tremaining: 1m 13s\n",
      "130:\tlearn: 71.8926267\ttotal: 43.4s\tremaining: 1m 13s\n",
      "131:\tlearn: 71.8864681\ttotal: 43.7s\tremaining: 1m 13s\n",
      "132:\tlearn: 71.8815808\ttotal: 44s\tremaining: 1m 12s\n",
      "133:\tlearn: 71.8764590\ttotal: 44.4s\tremaining: 1m 12s\n",
      "134:\tlearn: 71.8709160\ttotal: 44.7s\tremaining: 1m 12s\n",
      "135:\tlearn: 71.8651955\ttotal: 45.1s\tremaining: 1m 11s\n",
      "136:\tlearn: 71.8579782\ttotal: 45.5s\tremaining: 1m 11s\n",
      "137:\tlearn: 71.8565655\ttotal: 45.8s\tremaining: 1m 11s\n",
      "138:\tlearn: 71.8531154\ttotal: 46.2s\tremaining: 1m 11s\n",
      "139:\tlearn: 71.8457928\ttotal: 46.6s\tremaining: 1m 10s\n",
      "140:\tlearn: 71.8411134\ttotal: 47s\tremaining: 1m 10s\n",
      "141:\tlearn: 71.8342628\ttotal: 47.3s\tremaining: 1m 10s\n",
      "142:\tlearn: 71.8300580\ttotal: 47.7s\tremaining: 1m 9s\n",
      "143:\tlearn: 71.8246921\ttotal: 48s\tremaining: 1m 9s\n",
      "144:\tlearn: 71.8206553\ttotal: 48.5s\tremaining: 1m 9s\n",
      "145:\tlearn: 71.8123323\ttotal: 48.9s\tremaining: 1m 9s\n",
      "146:\tlearn: 71.8074398\ttotal: 49.3s\tremaining: 1m 9s\n",
      "147:\tlearn: 71.8029658\ttotal: 49.7s\tremaining: 1m 8s\n",
      "148:\tlearn: 71.7973101\ttotal: 50s\tremaining: 1m 8s\n",
      "149:\tlearn: 71.7967919\ttotal: 50.4s\tremaining: 1m 8s\n",
      "150:\tlearn: 71.7936310\ttotal: 50.7s\tremaining: 1m 7s\n",
      "151:\tlearn: 71.7910723\ttotal: 51.1s\tremaining: 1m 7s\n",
      "152:\tlearn: 71.7822239\ttotal: 51.4s\tremaining: 1m 7s\n",
      "153:\tlearn: 71.7776838\ttotal: 51.8s\tremaining: 1m 6s\n",
      "154:\tlearn: 71.7737687\ttotal: 52s\tremaining: 1m 6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "155:\tlearn: 71.7631959\ttotal: 52.4s\tremaining: 1m 6s\n",
      "156:\tlearn: 71.7551467\ttotal: 52.8s\tremaining: 1m 5s\n",
      "157:\tlearn: 71.7535960\ttotal: 53.1s\tremaining: 1m 5s\n",
      "158:\tlearn: 71.7440712\ttotal: 53.4s\tremaining: 1m 5s\n",
      "159:\tlearn: 71.7426241\ttotal: 53.8s\tremaining: 1m 4s\n",
      "160:\tlearn: 71.7383523\ttotal: 54.2s\tremaining: 1m 4s\n",
      "161:\tlearn: 71.7378562\ttotal: 54.4s\tremaining: 1m 4s\n",
      "162:\tlearn: 71.7332609\ttotal: 54.8s\tremaining: 1m 3s\n",
      "163:\tlearn: 71.7291948\ttotal: 55.2s\tremaining: 1m 3s\n",
      "164:\tlearn: 71.7217277\ttotal: 55.5s\tremaining: 1m 3s\n",
      "165:\tlearn: 71.7193912\ttotal: 55.9s\tremaining: 1m 2s\n",
      "166:\tlearn: 71.7155568\ttotal: 56.2s\tremaining: 1m 2s\n",
      "167:\tlearn: 71.7117349\ttotal: 56.6s\tremaining: 1m 2s\n",
      "168:\tlearn: 71.7039060\ttotal: 56.9s\tremaining: 1m 1s\n",
      "169:\tlearn: 71.6991943\ttotal: 57.4s\tremaining: 1m 1s\n",
      "170:\tlearn: 71.6952929\ttotal: 57.7s\tremaining: 1m 1s\n",
      "171:\tlearn: 71.6895215\ttotal: 58s\tremaining: 1m 1s\n",
      "172:\tlearn: 71.6862540\ttotal: 58.4s\tremaining: 1m\n",
      "173:\tlearn: 71.6826381\ttotal: 58.7s\tremaining: 1m\n",
      "174:\tlearn: 71.6769130\ttotal: 59.1s\tremaining: 1m\n",
      "175:\tlearn: 71.6707920\ttotal: 59.4s\tremaining: 59.8s\n",
      "176:\tlearn: 71.6632266\ttotal: 59.8s\tremaining: 59.4s\n",
      "177:\tlearn: 71.6580798\ttotal: 1m\tremaining: 59.1s\n",
      "178:\tlearn: 71.6577463\ttotal: 1m\tremaining: 58.8s\n",
      "179:\tlearn: 71.6537004\ttotal: 1m\tremaining: 58.4s\n",
      "180:\tlearn: 71.6490396\ttotal: 1m 1s\tremaining: 58.1s\n",
      "181:\tlearn: 71.6441569\ttotal: 1m 1s\tremaining: 57.7s\n",
      "182:\tlearn: 71.6388691\ttotal: 1m 1s\tremaining: 57.4s\n",
      "183:\tlearn: 71.6385817\ttotal: 1m 2s\tremaining: 57s\n",
      "184:\tlearn: 71.6351652\ttotal: 1m 2s\tremaining: 56.6s\n",
      "185:\tlearn: 71.6307077\ttotal: 1m 2s\tremaining: 56.3s\n",
      "186:\tlearn: 71.6255061\ttotal: 1m 3s\tremaining: 56s\n",
      "187:\tlearn: 71.6210349\ttotal: 1m 3s\tremaining: 55.6s\n",
      "188:\tlearn: 71.6181812\ttotal: 1m 3s\tremaining: 55.3s\n",
      "189:\tlearn: 71.6129994\ttotal: 1m 4s\tremaining: 55s\n",
      "190:\tlearn: 71.6091420\ttotal: 1m 4s\tremaining: 54.7s\n",
      "191:\tlearn: 71.6047772\ttotal: 1m 4s\tremaining: 54.4s\n",
      "192:\tlearn: 71.6013557\ttotal: 1m 5s\tremaining: 54.1s\n",
      "193:\tlearn: 71.5957152\ttotal: 1m 5s\tremaining: 53.9s\n",
      "194:\tlearn: 71.5921297\ttotal: 1m 6s\tremaining: 53.6s\n",
      "195:\tlearn: 71.5903294\ttotal: 1m 6s\tremaining: 53.5s\n",
      "196:\tlearn: 71.5864801\ttotal: 1m 7s\tremaining: 53.2s\n",
      "197:\tlearn: 71.5814271\ttotal: 1m 7s\tremaining: 52.9s\n",
      "198:\tlearn: 71.5778282\ttotal: 1m 8s\tremaining: 52.8s\n",
      "199:\tlearn: 71.5739915\ttotal: 1m 8s\tremaining: 52.5s\n",
      "200:\tlearn: 71.5737626\ttotal: 1m 8s\tremaining: 52.1s\n",
      "201:\tlearn: 71.5732996\ttotal: 1m 9s\tremaining: 51.8s\n",
      "202:\tlearn: 71.5687105\ttotal: 1m 9s\tremaining: 51.5s\n",
      "203:\tlearn: 71.5683078\ttotal: 1m 10s\tremaining: 51.2s\n",
      "204:\tlearn: 71.5641438\ttotal: 1m 10s\tremaining: 50.9s\n",
      "205:\tlearn: 71.5602819\ttotal: 1m 10s\tremaining: 50.5s\n",
      "206:\tlearn: 71.5555539\ttotal: 1m 11s\tremaining: 50.2s\n",
      "207:\tlearn: 71.5514379\ttotal: 1m 11s\tremaining: 49.9s\n",
      "208:\tlearn: 71.5477582\ttotal: 1m 11s\tremaining: 49.6s\n",
      "209:\tlearn: 71.5476651\ttotal: 1m 12s\tremaining: 49.2s\n",
      "210:\tlearn: 71.5437687\ttotal: 1m 12s\tremaining: 48.9s\n",
      "211:\tlearn: 71.5433559\ttotal: 1m 12s\tremaining: 48.5s\n",
      "212:\tlearn: 71.5389183\ttotal: 1m 13s\tremaining: 48.3s\n",
      "213:\tlearn: 71.5348176\ttotal: 1m 13s\tremaining: 48s\n",
      "214:\tlearn: 71.5300688\ttotal: 1m 14s\tremaining: 47.7s\n",
      "215:\tlearn: 71.5262756\ttotal: 1m 14s\tremaining: 47.3s\n",
      "216:\tlearn: 71.5218651\ttotal: 1m 15s\tremaining: 47s\n",
      "217:\tlearn: 71.5199721\ttotal: 1m 15s\tremaining: 46.7s\n",
      "218:\tlearn: 71.5198899\ttotal: 1m 15s\tremaining: 46.4s\n",
      "219:\tlearn: 71.5158672\ttotal: 1m 16s\tremaining: 46.1s\n",
      "220:\tlearn: 71.5119384\ttotal: 1m 16s\tremaining: 45.7s\n",
      "221:\tlearn: 71.5062374\ttotal: 1m 17s\tremaining: 45.5s\n",
      "222:\tlearn: 71.5027119\ttotal: 1m 17s\tremaining: 45.2s\n",
      "223:\tlearn: 71.4982368\ttotal: 1m 17s\tremaining: 44.8s\n",
      "224:\tlearn: 71.4939439\ttotal: 1m 18s\tremaining: 44.6s\n",
      "225:\tlearn: 71.4912307\ttotal: 1m 18s\tremaining: 44.3s\n",
      "226:\tlearn: 71.4872987\ttotal: 1m 19s\tremaining: 44s\n",
      "227:\tlearn: 71.4831206\ttotal: 1m 19s\tremaining: 43.7s\n",
      "228:\tlearn: 71.4798988\ttotal: 1m 20s\tremaining: 43.4s\n",
      "229:\tlearn: 71.4754027\ttotal: 1m 20s\tremaining: 43.1s\n",
      "230:\tlearn: 71.4736149\ttotal: 1m 21s\tremaining: 42.8s\n",
      "231:\tlearn: 71.4727039\ttotal: 1m 21s\tremaining: 42.5s\n",
      "232:\tlearn: 71.4693406\ttotal: 1m 21s\tremaining: 42.1s\n",
      "233:\tlearn: 71.4685814\ttotal: 1m 22s\tremaining: 41.8s\n",
      "234:\tlearn: 71.4647468\ttotal: 1m 22s\tremaining: 41.4s\n",
      "235:\tlearn: 71.4632849\ttotal: 1m 22s\tremaining: 41.1s\n",
      "236:\tlearn: 71.4597199\ttotal: 1m 23s\tremaining: 40.8s\n",
      "237:\tlearn: 71.4580850\ttotal: 1m 23s\tremaining: 40.4s\n",
      "238:\tlearn: 71.4539362\ttotal: 1m 24s\tremaining: 40.1s\n",
      "239:\tlearn: 71.4521034\ttotal: 1m 24s\tremaining: 39.7s\n",
      "240:\tlearn: 71.4486677\ttotal: 1m 24s\tremaining: 39.4s\n",
      "241:\tlearn: 71.4447139\ttotal: 1m 25s\tremaining: 39s\n",
      "242:\tlearn: 71.4420873\ttotal: 1m 25s\tremaining: 38.7s\n",
      "243:\tlearn: 71.4374000\ttotal: 1m 25s\tremaining: 38.4s\n",
      "244:\tlearn: 71.4342775\ttotal: 1m 26s\tremaining: 38s\n",
      "245:\tlearn: 71.4311076\ttotal: 1m 26s\tremaining: 37.7s\n",
      "246:\tlearn: 71.4309072\ttotal: 1m 26s\tremaining: 37.3s\n",
      "247:\tlearn: 71.4261383\ttotal: 1m 27s\tremaining: 37s\n",
      "248:\tlearn: 71.4228989\ttotal: 1m 27s\tremaining: 36.6s\n",
      "249:\tlearn: 71.4204030\ttotal: 1m 28s\tremaining: 36.3s\n",
      "250:\tlearn: 71.4164685\ttotal: 1m 28s\tremaining: 35.9s\n",
      "251:\tlearn: 71.4161772\ttotal: 1m 28s\tremaining: 35.6s\n",
      "252:\tlearn: 71.4136796\ttotal: 1m 29s\tremaining: 35.2s\n",
      "253:\tlearn: 71.4088657\ttotal: 1m 29s\tremaining: 34.9s\n",
      "254:\tlearn: 71.4053387\ttotal: 1m 29s\tremaining: 34.5s\n",
      "255:\tlearn: 71.4011509\ttotal: 1m 30s\tremaining: 34.2s\n",
      "256:\tlearn: 71.4010784\ttotal: 1m 30s\tremaining: 33.8s\n",
      "257:\tlearn: 71.3996582\ttotal: 1m 30s\tremaining: 33.4s\n",
      "258:\tlearn: 71.3949735\ttotal: 1m 31s\tremaining: 33.1s\n",
      "259:\tlearn: 71.3926848\ttotal: 1m 31s\tremaining: 32.7s\n",
      "260:\tlearn: 71.3887530\ttotal: 1m 31s\tremaining: 32.4s\n",
      "261:\tlearn: 71.3844778\ttotal: 1m 32s\tremaining: 32s\n",
      "262:\tlearn: 71.3788954\ttotal: 1m 32s\tremaining: 31.7s\n",
      "263:\tlearn: 71.3782955\ttotal: 1m 32s\tremaining: 31.3s\n",
      "264:\tlearn: 71.3777275\ttotal: 1m 33s\tremaining: 31s\n",
      "265:\tlearn: 71.3755182\ttotal: 1m 33s\tremaining: 30.6s\n",
      "266:\tlearn: 71.3706810\ttotal: 1m 34s\tremaining: 30.3s\n",
      "267:\tlearn: 71.3677044\ttotal: 1m 34s\tremaining: 29.9s\n",
      "268:\tlearn: 71.3629428\ttotal: 1m 34s\tremaining: 29.6s\n",
      "269:\tlearn: 71.3578226\ttotal: 1m 35s\tremaining: 29.2s\n",
      "270:\tlearn: 71.3537257\ttotal: 1m 35s\tremaining: 28.9s\n",
      "271:\tlearn: 71.3486918\ttotal: 1m 35s\tremaining: 28.5s\n",
      "272:\tlearn: 71.3478939\ttotal: 1m 36s\tremaining: 28.2s\n",
      "273:\tlearn: 71.3439474\ttotal: 1m 36s\tremaining: 27.8s\n",
      "274:\tlearn: 71.3396237\ttotal: 1m 36s\tremaining: 27.5s\n",
      "275:\tlearn: 71.3365032\ttotal: 1m 37s\tremaining: 27.1s\n",
      "276:\tlearn: 71.3311891\ttotal: 1m 37s\tremaining: 26.8s\n",
      "277:\tlearn: 71.3267018\ttotal: 1m 38s\tremaining: 26.5s\n",
      "278:\tlearn: 71.3225505\ttotal: 1m 38s\tremaining: 26.1s\n",
      "279:\tlearn: 71.3196470\ttotal: 1m 38s\tremaining: 25.8s\n",
      "280:\tlearn: 71.3140641\ttotal: 1m 39s\tremaining: 25.5s\n",
      "281:\tlearn: 71.3125787\ttotal: 1m 39s\tremaining: 25.1s\n",
      "282:\tlearn: 71.3089247\ttotal: 1m 40s\tremaining: 24.8s\n",
      "283:\tlearn: 71.3063009\ttotal: 1m 40s\tremaining: 24.4s\n",
      "284:\tlearn: 71.3026160\ttotal: 1m 40s\tremaining: 24.1s\n",
      "285:\tlearn: 71.3019832\ttotal: 1m 41s\tremaining: 23.7s\n",
      "286:\tlearn: 71.3000057\ttotal: 1m 41s\tremaining: 23.4s\n",
      "287:\tlearn: 71.2995700\ttotal: 1m 42s\tremaining: 23.1s\n",
      "288:\tlearn: 71.2963901\ttotal: 1m 42s\tremaining: 22.7s\n",
      "289:\tlearn: 71.2923436\ttotal: 1m 42s\tremaining: 22.4s\n",
      "290:\tlearn: 71.2906338\ttotal: 1m 43s\tremaining: 22s\n",
      "291:\tlearn: 71.2863786\ttotal: 1m 43s\tremaining: 21.7s\n",
      "292:\tlearn: 71.2822557\ttotal: 1m 44s\tremaining: 21.4s\n",
      "293:\tlearn: 71.2804995\ttotal: 1m 44s\tremaining: 21s\n",
      "294:\tlearn: 71.2769193\ttotal: 1m 45s\tremaining: 20.6s\n",
      "295:\tlearn: 71.2760038\ttotal: 1m 45s\tremaining: 20.3s\n",
      "296:\tlearn: 71.2728883\ttotal: 1m 45s\tremaining: 19.9s\n",
      "297:\tlearn: 71.2703669\ttotal: 1m 46s\tremaining: 19.6s\n",
      "298:\tlearn: 71.2687984\ttotal: 1m 46s\tremaining: 19.2s\n",
      "299:\tlearn: 71.2664902\ttotal: 1m 46s\tremaining: 18.9s\n",
      "300:\tlearn: 71.2631886\ttotal: 1m 47s\tremaining: 18.5s\n",
      "301:\tlearn: 71.2600914\ttotal: 1m 47s\tremaining: 18.2s\n",
      "302:\tlearn: 71.2599896\ttotal: 1m 47s\tremaining: 17.8s\n",
      "303:\tlearn: 71.2568115\ttotal: 1m 48s\tremaining: 17.4s\n",
      "304:\tlearn: 71.2556036\ttotal: 1m 48s\tremaining: 17.1s\n",
      "305:\tlearn: 71.2524464\ttotal: 1m 49s\tremaining: 16.8s\n",
      "306:\tlearn: 71.2481868\ttotal: 1m 49s\tremaining: 16.4s\n",
      "307:\tlearn: 71.2478466\ttotal: 1m 49s\tremaining: 16.1s\n",
      "308:\tlearn: 71.2441462\ttotal: 1m 50s\tremaining: 15.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "309:\tlearn: 71.2436487\ttotal: 1m 50s\tremaining: 15.3s\n",
      "310:\tlearn: 71.2410837\ttotal: 1m 51s\tremaining: 15s\n",
      "311:\tlearn: 71.2372661\ttotal: 1m 51s\tremaining: 14.6s\n",
      "312:\tlearn: 71.2347885\ttotal: 1m 51s\tremaining: 14.3s\n",
      "313:\tlearn: 71.2317035\ttotal: 1m 52s\tremaining: 13.9s\n",
      "314:\tlearn: 71.2286404\ttotal: 1m 52s\tremaining: 13.6s\n",
      "315:\tlearn: 71.2239756\ttotal: 1m 52s\tremaining: 13.2s\n",
      "316:\tlearn: 71.2211650\ttotal: 1m 53s\tremaining: 12.9s\n",
      "317:\tlearn: 71.2186969\ttotal: 1m 53s\tremaining: 12.5s\n",
      "318:\tlearn: 71.2151913\ttotal: 1m 53s\tremaining: 12.1s\n",
      "319:\tlearn: 71.2143531\ttotal: 1m 54s\tremaining: 11.8s\n",
      "320:\tlearn: 71.2129551\ttotal: 1m 54s\tremaining: 11.4s\n",
      "321:\tlearn: 71.2096009\ttotal: 1m 55s\tremaining: 11.1s\n",
      "322:\tlearn: 71.2074240\ttotal: 1m 55s\tremaining: 10.7s\n",
      "323:\tlearn: 71.2041697\ttotal: 1m 55s\tremaining: 10.4s\n",
      "324:\tlearn: 71.2011995\ttotal: 1m 56s\tremaining: 10s\n",
      "325:\tlearn: 71.1975813\ttotal: 1m 56s\tremaining: 9.65s\n",
      "326:\tlearn: 71.1942232\ttotal: 1m 56s\tremaining: 9.29s\n",
      "327:\tlearn: 71.1910273\ttotal: 1m 57s\tremaining: 8.94s\n",
      "328:\tlearn: 71.1895754\ttotal: 1m 57s\tremaining: 8.58s\n",
      "329:\tlearn: 71.1892249\ttotal: 1m 57s\tremaining: 8.22s\n",
      "330:\tlearn: 71.1847107\ttotal: 1m 58s\tremaining: 7.87s\n",
      "331:\tlearn: 71.1827731\ttotal: 1m 58s\tremaining: 7.51s\n",
      "332:\tlearn: 71.1782298\ttotal: 1m 59s\tremaining: 7.15s\n",
      "333:\tlearn: 71.1770326\ttotal: 1m 59s\tremaining: 6.8s\n",
      "334:\tlearn: 71.1735155\ttotal: 1m 59s\tremaining: 6.44s\n",
      "335:\tlearn: 71.1702458\ttotal: 2m\tremaining: 6.08s\n",
      "336:\tlearn: 71.1696217\ttotal: 2m\tremaining: 5.72s\n",
      "337:\tlearn: 71.1664376\ttotal: 2m\tremaining: 5.37s\n",
      "338:\tlearn: 71.1627813\ttotal: 2m 1s\tremaining: 5.01s\n",
      "339:\tlearn: 71.1591611\ttotal: 2m 1s\tremaining: 4.65s\n",
      "340:\tlearn: 71.1566647\ttotal: 2m 2s\tremaining: 4.29s\n",
      "341:\tlearn: 71.1562778\ttotal: 2m 2s\tremaining: 3.94s\n",
      "342:\tlearn: 71.1531348\ttotal: 2m 2s\tremaining: 3.58s\n",
      "343:\tlearn: 71.1513140\ttotal: 2m 3s\tremaining: 3.22s\n",
      "344:\tlearn: 71.1479552\ttotal: 2m 3s\tremaining: 2.86s\n",
      "345:\tlearn: 71.1466360\ttotal: 2m 3s\tremaining: 2.5s\n",
      "346:\tlearn: 71.1448048\ttotal: 2m 4s\tremaining: 2.15s\n",
      "347:\tlearn: 71.1401400\ttotal: 2m 4s\tremaining: 1.79s\n",
      "348:\tlearn: 71.1367076\ttotal: 2m 4s\tremaining: 1.43s\n",
      "349:\tlearn: 71.1333223\ttotal: 2m 5s\tremaining: 1.07s\n",
      "350:\tlearn: 71.1299941\ttotal: 2m 5s\tremaining: 716ms\n",
      "351:\tlearn: 71.1262198\ttotal: 2m 6s\tremaining: 358ms\n",
      "352:\tlearn: 71.1233848\ttotal: 2m 6s\tremaining: 0us\n"
     ]
    }
   ],
   "source": [
    "test_pool = Pool(test.drop([\"id\"], axis=1), \n",
    "                 cat_features=list(range(10)) + [24])\n",
    "\n",
    "model = CatBoostRegressor(**params)\n",
    "#train the model\n",
    "model.fit(train_pool)\n",
    "# make the prediction using the resulting model\n",
    "preds = model.predict(test_pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['target'] = preds/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cat0</th>\n",
       "      <th>cat1</th>\n",
       "      <th>cat2</th>\n",
       "      <th>cat3</th>\n",
       "      <th>cat4</th>\n",
       "      <th>cat5</th>\n",
       "      <th>cat6</th>\n",
       "      <th>cat7</th>\n",
       "      <th>cat8</th>\n",
       "      <th>cat9</th>\n",
       "      <th>cont0</th>\n",
       "      <th>cont1</th>\n",
       "      <th>cont2</th>\n",
       "      <th>cont3</th>\n",
       "      <th>cont4</th>\n",
       "      <th>cont5</th>\n",
       "      <th>cont6</th>\n",
       "      <th>cont7</th>\n",
       "      <th>cont8</th>\n",
       "      <th>cont9</th>\n",
       "      <th>cont10</th>\n",
       "      <th>cont11</th>\n",
       "      <th>cont12</th>\n",
       "      <th>cont13</th>\n",
       "      <th>anomaly_col</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>C</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>E</td>\n",
       "      <td>I</td>\n",
       "      <td>0.296227</td>\n",
       "      <td>0.686757</td>\n",
       "      <td>0.587731</td>\n",
       "      <td>0.392753</td>\n",
       "      <td>0.476739</td>\n",
       "      <td>0.376350</td>\n",
       "      <td>0.337884</td>\n",
       "      <td>0.321832</td>\n",
       "      <td>0.445212</td>\n",
       "      <td>0.290258</td>\n",
       "      <td>0.244476</td>\n",
       "      <td>0.087914</td>\n",
       "      <td>0.301831</td>\n",
       "      <td>0.845702</td>\n",
       "      <td>0</td>\n",
       "      <td>8.007290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>B</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>C</td>\n",
       "      <td>H</td>\n",
       "      <td>0.543707</td>\n",
       "      <td>0.364761</td>\n",
       "      <td>0.452967</td>\n",
       "      <td>0.929645</td>\n",
       "      <td>0.285509</td>\n",
       "      <td>0.860046</td>\n",
       "      <td>0.798712</td>\n",
       "      <td>0.835961</td>\n",
       "      <td>0.391657</td>\n",
       "      <td>0.288276</td>\n",
       "      <td>0.549568</td>\n",
       "      <td>0.905097</td>\n",
       "      <td>0.850684</td>\n",
       "      <td>0.693940</td>\n",
       "      <td>0</td>\n",
       "      <td>8.321461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>D</td>\n",
       "      <td>K</td>\n",
       "      <td>0.408961</td>\n",
       "      <td>0.296129</td>\n",
       "      <td>0.690999</td>\n",
       "      <td>0.740027</td>\n",
       "      <td>0.697272</td>\n",
       "      <td>0.683600</td>\n",
       "      <td>0.404089</td>\n",
       "      <td>0.879379</td>\n",
       "      <td>0.275549</td>\n",
       "      <td>0.427871</td>\n",
       "      <td>0.491667</td>\n",
       "      <td>0.384315</td>\n",
       "      <td>0.376689</td>\n",
       "      <td>0.508099</td>\n",
       "      <td>0</td>\n",
       "      <td>8.361042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>B</td>\n",
       "      <td>D</td>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>A</td>\n",
       "      <td>N</td>\n",
       "      <td>1.031239</td>\n",
       "      <td>0.356062</td>\n",
       "      <td>0.303651</td>\n",
       "      <td>0.895591</td>\n",
       "      <td>0.719306</td>\n",
       "      <td>0.777890</td>\n",
       "      <td>0.730954</td>\n",
       "      <td>0.644315</td>\n",
       "      <td>1.024017</td>\n",
       "      <td>0.391090</td>\n",
       "      <td>0.988340</td>\n",
       "      <td>0.411828</td>\n",
       "      <td>0.393585</td>\n",
       "      <td>0.461372</td>\n",
       "      <td>0</td>\n",
       "      <td>8.530366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>B</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "      <td>C</td>\n",
       "      <td>F</td>\n",
       "      <td>0.530447</td>\n",
       "      <td>0.729004</td>\n",
       "      <td>0.281723</td>\n",
       "      <td>0.444698</td>\n",
       "      <td>0.313032</td>\n",
       "      <td>0.431007</td>\n",
       "      <td>0.390992</td>\n",
       "      <td>0.408874</td>\n",
       "      <td>0.447887</td>\n",
       "      <td>0.390253</td>\n",
       "      <td>0.648932</td>\n",
       "      <td>0.385935</td>\n",
       "      <td>0.370401</td>\n",
       "      <td>0.900412</td>\n",
       "      <td>0</td>\n",
       "      <td>8.136185</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id cat0 cat1 cat2 cat3 cat4 cat5 cat6 cat7 cat8 cat9     cont0     cont1  \\\n",
       "0   0    B    B    B    C    B    B    A    E    E    I  0.296227  0.686757   \n",
       "1   5    A    B    A    C    B    C    A    E    C    H  0.543707  0.364761   \n",
       "2  15    B    A    A    A    B    B    A    E    D    K  0.408961  0.296129   \n",
       "3  16    B    B    A    C    B    D    A    E    A    N  1.031239  0.356062   \n",
       "4  17    B    B    A    C    B    C    A    E    C    F  0.530447  0.729004   \n",
       "\n",
       "      cont2     cont3     cont4     cont5     cont6     cont7     cont8  \\\n",
       "0  0.587731  0.392753  0.476739  0.376350  0.337884  0.321832  0.445212   \n",
       "1  0.452967  0.929645  0.285509  0.860046  0.798712  0.835961  0.391657   \n",
       "2  0.690999  0.740027  0.697272  0.683600  0.404089  0.879379  0.275549   \n",
       "3  0.303651  0.895591  0.719306  0.777890  0.730954  0.644315  1.024017   \n",
       "4  0.281723  0.444698  0.313032  0.431007  0.390992  0.408874  0.447887   \n",
       "\n",
       "      cont9    cont10    cont11    cont12    cont13  anomaly_col    target  \n",
       "0  0.290258  0.244476  0.087914  0.301831  0.845702            0  8.007290  \n",
       "1  0.288276  0.549568  0.905097  0.850684  0.693940            0  8.321461  \n",
       "2  0.427871  0.491667  0.384315  0.376689  0.508099            0  8.361042  \n",
       "3  0.391090  0.988340  0.411828  0.393585  0.461372            0  8.530366  \n",
       "4  0.390253  0.648932  0.385935  0.370401  0.900412            0  8.136185  "
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[['id', 'target']].to_csv('catboost_anomaly.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
